{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from importlib import reload\n",
    "import IPython\n",
    "mpl.rcParams['lines.linewidth'] = 0.25\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.linewidth'] = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, argparse, os, shutil, inspect, json, numpy\n",
    "import netdissect\n",
    "from netdissect.easydict import EasyDict\n",
    "from netdissect import pbar, nethook, renormalize, parallelfolder, pidfile\n",
    "from netdissect import upsample, tally, imgviz, imgsave, bargraph, show\n",
    "from experiment import dissect_experiment as experiment\n",
    "\n",
    "args = EasyDict(model='progan', dataset='church', seg='netpqc', quantile=0.01, layer='layer4')\n",
    "resdir = 'results/%s-%s-%s-%s-%s' % (args.model, args.dataset, args.seg, args.layer, int(args.quantile * 1000))\n",
    "def resfile(f):\n",
    "    return os.path.join(resdir, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = experiment.load_model(args)\n",
    "layername = experiment.instrumented_layername(args)\n",
    "model.retain_layer(layername)\n",
    "dataset = experiment.load_dataset(args, model.model)\n",
    "upfn = experiment.make_upfn(args, dataset, model, layername)\n",
    "sample_size = len(dataset)\n",
    "percent_level = 1 - args.quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netdissect import renormalize\n",
    "\n",
    "segmodel, seglabels, segcatlabels = experiment.setting.load_segmenter(args.seg)\n",
    "renorm = renormalize.renormalizer(target='zc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar.descnext('rq')\n",
    "def compute_samples(batch, *args):\n",
    "    z_batch = batch.cuda()\n",
    "    _ = model(z_batch)\n",
    "    acts = model.retained_layer(layername)\n",
    "    hacts = upfn(acts)\n",
    "    return hacts.permute(0, 2, 3, 1).contiguous().view(-1, acts.shape[1])\n",
    "rq = tally.tally_quantile(compute_samples, dataset,\n",
    "                          sample_size=sample_size,\n",
    "                          r=8192,\n",
    "                          num_workers=100,\n",
    "                          pin_memory=True,\n",
    "                          cachefile=resfile('rq.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conditional_indicator(batch, *args):\n",
    "    data_batch = batch.cuda()\n",
    "    out_batch = model(data_batch)\n",
    "    image_batch = out_batch\n",
    "    seg = segmodel.segment_batch(image_batch, downsample=4)\n",
    "    acts = model.retained_layer(layername)\n",
    "    hacts = upfn(acts)\n",
    "    iacts = (hacts > level_at_99).float() # indicator\n",
    "    return tally.conditional_samples(iacts, seg)\n",
    "\n",
    "pbar.descnext('condi99')\n",
    "condi99 = tally.tally_conditional_mean(compute_conditional_indicator,\n",
    "        dataset, sample_size=sample_size,\n",
    "        num_workers=3, pin_memory=True,\n",
    "        cachefile=resfile('condi99.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_99 = tally.iou_from_conditional_indicator_mean(condi99)\n",
    "unit_label_99 = [\n",
    "        (concept.item(), seglabels[concept], segcatlabels[concept], bestiou.item())\n",
    "        for (bestiou, concept) in zip(*iou_99.max(0))]\n",
    "label_list = [labelcat for concept, label, labelcat, iou in unit_label_99 if iou > 0.04]\n",
    "display(IPython.display.SVG(experiment.graph_conceptcatlist(label_list)))\n",
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segindex = seglabels.index('tree')\n",
    "tree_units = (-iou_99[segindex]).sort(0)[1][:20]\n",
    "tree_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from netdissect import renormalize\n",
    "\n",
    "indices = [489, 200, 726, 803, 920, 926] #range(200,224)\n",
    "batch = torch.cat([dataset[i][0][None,...] for i in indices])\n",
    "outs = model(batch.cuda())\n",
    "imgs = [renormalize.as_image(t) for t in outs]\n",
    "show([[img] for img in imgs])\n",
    "\n",
    "def zero_tree_units(x, *args):\n",
    "    x[:, tree_units] = 0\n",
    "    return x\n",
    "model.edit_layer(layername, rule=zero_tree_units)\n",
    "outs = model(batch.cuda())\n",
    "imgs = [renormalize.as_image(t) for t in outs]\n",
    "show([[img] for img in imgs])\n",
    "model.remove_edits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_segclass_with_zeroed_units(segclass, zeroed_units, sample_size=100):\n",
    "    model.remove_edits()\n",
    "    def zero_some_units(x, *args):\n",
    "        x[:, zeroed_units] = 0\n",
    "        return x\n",
    "    model.edit_layer(layername, rule=zero_some_units)\n",
    "    def compute_mean_seg_in_images(batch_z, *args):\n",
    "        img = model(batch_z.cuda())\n",
    "        seg = segmodel.segment_batch(img, downsample=4)\n",
    "        segmatch = (seg == segclass).max(1)[0].float().view(seg.shape[0], -1).sum(1)\n",
    "        # Express in units of fractions of an image\n",
    "        return segmatch[:,None] / (seg.shape[2] * seg.shape[3])\n",
    "    result = tally.tally_mean(compute_mean_seg_in_images, dataset,\n",
    "                            batch_size=30, sample_size=sample_size, pin_memory=True)\n",
    "    model.remove_edits()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_segclasses_with_zeroed_units(zeroed_units, sample_size=100):\n",
    "    model.remove_edits()\n",
    "    def zero_some_units(x, *args):\n",
    "        x[:, zeroed_units] = 0\n",
    "        return x\n",
    "    model.edit_layer(layername, rule=zero_some_units)\n",
    "    num_seglabels = len(segmodel.get_label_and_category_names()[0])\n",
    "    def compute_mean_seg_in_images(batch_z, *args):\n",
    "        img = model(batch_z.cuda())\n",
    "        seg = segmodel.segment_batch(img, downsample=4)\n",
    "        seg_area = seg.shape[2] * seg.shape[3]\n",
    "        seg_counts = torch.bincount((seg + (num_seglabels *\n",
    "            torch.arange(seg.shape[0], dtype=seg.dtype, device=seg.device)[:,None,None,None])).view(-1),\n",
    "            minlength=num_seglabels * seg.shape[0]).view(seg.shape[0], -1)\n",
    "        seg_fracs = seg_counts.float() / seg_area\n",
    "        return seg_fracs\n",
    "    result = tally.tally_mean(compute_mean_seg_in_images, dataset,\n",
    "                            batch_size=30, sample_size=sample_size, pin_memory=True)\n",
    "    model.remove_edits()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs_baseline = measure_segclasses_with_zeroed_units([])\n",
    "segs_without_treeunits = measure_segclasses_with_zeroed_units(tree_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(segs_baseline.mean()[:10], segs_baseline.stdev())\n",
    "print(segs_without_treeunits.mean()[:10], segs_without_treeunits.stdev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_units = len(unit_label_99)\n",
    "baseline_segmean = experiment.test_generator_segclass_stats(model, dataset, segmodel,\n",
    "            layername=layername,\n",
    "            cachefile=resfile('segstats/baseline.npz')).mean()\n",
    "unit_ablation_segmean = torch.zeros(num_units, len(baseline_segmean))\n",
    "for unit in range(num_units):\n",
    "    unit_ablation_segmean[unit] = experiment.test_generator_segclass_stats(model, dataset, segmodel,\n",
    "                layername=layername, zeroed_units=[unit],\n",
    "                cachefile=resfile('segstats/ablated_unit_%d.npz' % unit)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros([])\n",
    "a[None] = 1.0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablate_segclass_name = 'tree'\n",
    "ablate_segclass = seglabels.index(ablate_segclass_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ss_units = unit_ablation_segmean[:,ablate_segclass].sort(0)[1]\n",
    "best_ss_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_ablation_segmean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iou_units = iou_99[ablate_segclass,:].sort(0)[1].flip(0)\n",
    "best_iou_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "byiou_unit_ablation_seg = torch.zeros(1)\n",
    "byiou_unit_ablation_seg_stdev = torch.zeros(1)\n",
    "for unitcount in range(0,1):\n",
    "    zero_units = best_iou_units[:unitcount].tolist()\n",
    "    stats = experiment.test_generator_segclass_stats(model, dataset, segmodel,\n",
    "                layername=layername, zeroed_units=zero_units,\n",
    "                cachefile=resfile('segstats/ablated_best_%d_iou_%s.npz' %\n",
    "                    (unitcount, ablate_segclass_name)))\n",
    "    byiou_unit_ablation_seg[unitcount] = stats.mean()[ablate_segclass]  \n",
    "    byiou_unit_ablation_seg_stdev[unitcount] = stats.stdev()[ablate_segclass]\n",
    "byiou_unit_ablation_delta_seg = torch.zeros(31)\n",
    "byiou_unit_ablation_delta_seg_stdev = torch.zeros(31)\n",
    "byiou_unit_ablation_delta_seg_stderr = torch.zeros(31)\n",
    "for unitcount in range(0,31):\n",
    "    zero_units = best_iou_units[:unitcount].tolist()\n",
    "    stats = experiment.test_generator_segclass_delta_stats(model, dataset, segmodel,\n",
    "                layername=layername, zeroed_units=zero_units,\n",
    "                cachefile=resfile('deltasegstats/ablated_best_%d_iou_%s.npz' %\n",
    "                    (unitcount, ablate_segclass_name)))\n",
    "    byiou_unit_ablation_delta_seg[unitcount] = stats.mean()[ablate_segclass]  \n",
    "    byiou_unit_ablation_delta_seg_stdev[unitcount] = stats.stdev()[ablate_segclass]\n",
    "    byiou_unit_ablation_delta_seg_stderr[unitcount] = stats.stdev()[ablate_segclass] / math.sqrt(stats.size())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,3), dpi=300)\n",
    "# y = 1 - byiou_unit_ablation_seg.numpy()/byiou_unit_ablation_seg.numpy()[0]\n",
    "y = -byiou_unit_ablation_delta_seg.numpy()/byiou_unit_ablation_seg.numpy()[0]\n",
    "yerr = byiou_unit_ablation_delta_seg_stderr.numpy()/byiou_unit_ablation_seg.numpy()[0]\n",
    "ax.plot(y, linewidth=2, color=\"#4B4CBF\")\n",
    "ax.fill_between(range(len(y)), y-yerr*2.58, y+yerr*2.56,\n",
    "                edgecolor='#55B05B', facecolor='#55B05B',\n",
    "    antialiased=True)\n",
    "ax.set_ylim([0,0.7])\n",
    "#ax.set_xlabel('Number of units removed (units ranked by IoU with trees)')\n",
    "ax.set_ylabel('Portion of tree pixels removed')\n",
    "ax.set_xticks([0, 2, 4, 8, 20, 30])\n",
    "ax.set_yticklabels(['{:,.0%}'.format(x) for x in ax.get_yticks()])\n",
    "ax.grid(linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byiou_unit_ablation_delta_seg_stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byiou_unit_ablation_seg_stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byiou_unit_ablation_delta_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot((unit_ablation_segmean[:,4] / baseline_segmean[4]).sort(0)[0].numpy()[:30], linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from netdissect import renormalize\n",
    "indices = [489, 726, 920, 926] #range(200,224)\n",
    "batch = torch.cat([dataset[i][0][None,...] for i in indices])\n",
    "\n",
    "for unit_count in [0, 2, 4, 8, 20]:\n",
    "    tree_units = best_iou_units[:unit_count]\n",
    "    def zero_tree_units(x, *args):\n",
    "        x[:, tree_units] = 0\n",
    "        return x\n",
    "    model.remove_edits()\n",
    "    model.edit_layer(layername, rule=zero_tree_units)\n",
    "    outs = model(batch.cuda())\n",
    "    imgs = [renormalize.as_image(t) for t in outs]\n",
    "    show([[img] for img in imgs])\n",
    "    model.remove_edits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_segclass = seglabels.index('door')\n",
    "door_segclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_units = iou_99[door_segclass].sort(0)[1].flip(0)[:20]\n",
    "door_high_values = rq.quantiles(0.995)[door_units].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "door_high_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from netdissect import segviz\n",
    "\n",
    "def add_yellow_box(timg, y1, y2, x1, x2, thickness):\n",
    "    yellow = torch.tensor([1.0, 1.0, 0.0], dtype=timg.dtype, device=timg.device)[None, :, None, None]\n",
    "    def yclip(c):\n",
    "        return max(0, min(timg.shape[2], c))\n",
    "    def xclip(c):\n",
    "        return max(0, min(timg.shape[3], c))\n",
    "    \n",
    "    timg[:, :, yclip(y1):yclip(y2+thickness), xclip(x1):xclip(x1+thickness)] = yellow\n",
    "    timg[:, :, yclip(y1):yclip(y2+thickness), xclip(x2):xclip(x2+thickness)] = yellow\n",
    "    timg[:, :, yclip(y1):yclip(y1+thickness), xclip(x1):xclip(x2+thickness)] = yellow\n",
    "    timg[:, :, yclip(y2):yclip(y2+thickness), xclip(x1):xclip(x2+thickness)] = yellow\n",
    "    return timg\n",
    "indices = [726] #[489, 726, 920, 926] #range(200,224)\n",
    "\n",
    "\n",
    "for index in pbar([591, 589, 561, 422, 499, 315, 361, 396, 19, 25, 71, 151, 159, 167, 188, 279, ]):\n",
    "    indices = [index]\n",
    "    batch = torch.cat([dataset[i][0][None,...] for i in indices])\n",
    "    batchc = batch.cuda()[:1]\n",
    "    model.remove_edits()\n",
    "    orig_img = model(batchc)\n",
    "    orig_seg = segmodel.segment_batch(orig_img, downsample=4)\n",
    "    orig_door = (orig_seg == door_segclass).view(len(batchc), -1).sum(1)\n",
    "    rep = model.retained_layer(layername).clone()\n",
    "    ysize = orig_seg.shape[2] // rep.shape[2]\n",
    "    xsize = orig_seg.shape[3] // rep.shape[3]\n",
    "    for y in range(rep.shape[2]):\n",
    "        for x in range(rep.shape[3]):\n",
    "            changed_rep = rep.clone()\n",
    "            changed_rep[:,door_units,y,x] = door_high_values[None,:]\n",
    "            # def subst(x, *args):\n",
    "            #    return changed_rep\n",
    "            # model.edit_layer(layername, rule=subst) # lambda x, ctx: changed_rep) # ablation=0.5, replacement=changed_rep)\n",
    "            model.edit_layer(layername, ablation=1.0, replacement=changed_rep)\n",
    "            changed_img = model(batchc)\n",
    "            changed_seg = segmodel.segment_batch(changed_img, downsample=4)\n",
    "            changed_door = (changed_seg == door_segclass).view(len(batchc), -1).sum(1)\n",
    "            if (changed_door - orig_door).max().item() > 2:\n",
    "                selsegs = orig_seg[:,:,y*ysize+ysize//2,x*xsize+xsize//2].view(-1)\n",
    "                orig_img_copy = orig_img.clone()\n",
    "                add_yellow_box(orig_img_copy, y*32-1, (y+1)*32-1, x*32-1, (x+1)*32-1, 2)\n",
    "                existing = ' '.join([seglabels[sc] for sc in selsegs if sc != 0])\n",
    "                show([['#%d %d %d repd %.2f rgbd %.2f doord %.1f %s' %\n",
    "                       (index, y, x, (changed_rep - rep).max().item(),\n",
    "                        (changed_img - orig_img).max().item(),\n",
    "                        (changed_door - orig_door).max().item(),\n",
    "                        existing\n",
    "                       ),\n",
    "                       [renormalize.as_image(orig_img_copy[0])],\n",
    "                       [renormalize.as_image(img)],\n",
    "                       # [segviz.seg_as_image(orig_seg[i, 2:3], size=256)],\n",
    "                       [segviz.seg_as_image(changed_seg[i, 2:3], size=256)],\n",
    "                       [segviz.segment_key(changed_seg[i, 2:3], segmodel, 10)]]\n",
    "                      for i, img in enumerate(changed_img)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, coordlist in pbar([\n",
    "    (151, [(5, 3), (5, 5)]),\n",
    "    (279, [(5, 3), (5, 5)]),\n",
    "]):\n",
    "    indices = [index]\n",
    "    batch = torch.cat([dataset[i][0][None,...] for i in indices])\n",
    "    batchc = batch.cuda()[:1]\n",
    "    model.remove_edits()\n",
    "    orig_img = model(batchc)\n",
    "    orig_seg = segmodel.segment_batch(orig_img, downsample=4)\n",
    "    orig_door = (orig_seg == door_segclass).view(len(batchc), -1).sum(1)\n",
    "    rep = model.retained_layer(layername).clone()\n",
    "    ysize = orig_seg.shape[2] // rep.shape[2]\n",
    "    xsize = orig_seg.shape[3] // rep.shape[3]\n",
    "    for y, x in coordlist:\n",
    "        changed_rep = rep.clone()\n",
    "        changed_rep[:,door_units,y,x] = door_high_values[None,:]\n",
    "        # def subst(x, *args):\n",
    "        #    return changed_rep\n",
    "        # model.edit_layer(layername, rule=subst) # lambda x, ctx: changed_rep) # ablation=0.5, replacement=changed_rep)\n",
    "        model.edit_layer(layername, ablation=1.0, replacement=changed_rep)\n",
    "        changed_img = model(batchc)\n",
    "        changed_seg = segmodel.segment_batch(changed_img, downsample=4)\n",
    "        changed_door = (changed_seg == door_segclass).view(len(batchc), -1).sum(1)\n",
    "        selsegs = orig_seg[:,:,y*ysize+ysize//2,x*xsize+xsize//2].view(-1)\n",
    "        # orig_img_copy = orig_img.clone()\n",
    "        add_yellow_box(orig_img, y*32-1, (y+1)*32-1, x*32-1, (x+1)*32-1, 2)\n",
    "        existing = ' '.join([seglabels[sc] for sc in selsegs if sc != 0])\n",
    "        show([['#%d %d %d repd %.2f rgbd %.2f doord %.1f %s' %\n",
    "               (index, y, x, (changed_rep - rep).max().item(),\n",
    "                (changed_img - orig_img).max().item(),\n",
    "                (changed_door - orig_door).max().item(),\n",
    "                existing\n",
    "               ),\n",
    "               [renormalize.as_image(orig_img[0])],\n",
    "               [renormalize.as_image(img)],\n",
    "               # [segviz.seg_as_image(orig_seg[i, 2:3], size=256)],\n",
    "               [segviz.seg_as_image(changed_seg[i, 2:3], size=256)],\n",
    "               [segviz.segment_key(changed_seg[i, 2:3], segmodel, 10)]]\n",
    "              for i, img in enumerate(changed_img)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_segclass = len(seglabels)\n",
    "num_segclass\n",
    "\n",
    "def batch_bincount(data, num_labels):\n",
    "    data = data.view(len(data), -1)\n",
    "    strided = data + torch.arange(len(data), dtype=data.dtype, device=data.device)[:,None] * num_labels\n",
    "    counts = torch.bincount(strided.view(-1), minlength=num_labels * len(data))\n",
    "    return counts.view(len(data), num_labels)\n",
    "\n",
    "def compute_seg_impact(zbatch, *args):\n",
    "    zbatch = zbatch.cuda()\n",
    "    model.remove_edits()\n",
    "    orig_img = model(zbatch)\n",
    "    orig_seg = segmodel.segment_batch(orig_img, downsample=4)\n",
    "    orig_segcount = batch_bincount(orig_seg, num_segclass)\n",
    "    rep = model.retained_layer(layername).clone()\n",
    "    ysize = orig_seg.shape[2] // rep.shape[2]\n",
    "    xsize = orig_seg.shape[3] // rep.shape[3]\n",
    "    def gen_conditions():\n",
    "        for y in range(rep.shape[2]):\n",
    "            for x in range(rep.shape[3]):\n",
    "                # Take as the context location the segmentation labels at the center of the square.\n",
    "                selsegs = orig_seg[:,:,y*ysize+ysize//2,x*xsize+xsize//2]\n",
    "                changed_rep = rep.clone()\n",
    "                changed_rep[:,door_units,y,x] = door_high_values[None,:]\n",
    "                model.edit_layer(layername, ablation=1.0, replacement=changed_rep)\n",
    "                changed_img = model(zbatch)\n",
    "                changed_seg = segmodel.segment_batch(changed_img, downsample=4)\n",
    "                changed_segcount = batch_bincount(changed_seg, num_segclass)\n",
    "                delta_segcount = (changed_segcount - orig_segcount).float()\n",
    "                for sel, delta in zip(selsegs, delta_segcount):\n",
    "                    for cond in torch.bincount(sel).nonzero()[:,0]:\n",
    "                        if cond == 0:\n",
    "                            continue\n",
    "                        yield (cond.item(), delta)\n",
    "    return gen_conditions()\n",
    "\n",
    "cond_changes = tally.tally_conditional_mean(compute_seg_impact, dataset, sample_size=10000, batch_size=20,\n",
    "                                           cachefile=resfile('big_door_cond_changes.npz'))\n",
    "cond_changes\n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_seg_counts(zbatch, *args):\n",
    "    zbatch = zbatch.cuda()\n",
    "    model.remove_edits()\n",
    "    orig_img = model(zbatch)\n",
    "    orig_seg = segmodel.segment_batch(orig_img, downsample=4)\n",
    "    orig_segcount = batch_bincount(orig_seg, num_segclass)\n",
    "    return orig_segcount.float()\n",
    "\n",
    "baseline_segcounts = tally.tally_mean(compute_seg_counts, dataset, sample_size=10000, batch_size=100,\n",
    "                                     cachefile=resfile('baseline_segcounts.npz'))\n",
    "baseline_segcounts\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_door = baseline_segcounts.mean()[seglabels.index('door')].item()\n",
    "baseline_door"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([(k, seglabels[k], cond_changes.conditional(k).size(),\n",
    "         cond_changes.conditional(k).mean()[seglabels.index('door')].item() / baseline_door)\n",
    " for k in cond_changes.keys()\n",
    " if cond_changes.conditional(k).size() >= 1000], key=lambda x: -x[-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,3), dpi=300)\n",
    "glabels = ['window', 'stairway', 'building', 'grass', 'tree', 'sky']\n",
    "ax.bar(range(len(glabels)), [\n",
    "    cond_changes.conditional(seglabels.index(gl)).mean()[seglabels.index('door')].item()\n",
    "    / baseline_door\n",
    "    for gl in glabels],\n",
    "    yerr=[ math.sqrt(\n",
    "        cond_changes.conditional(seglabels.index(gl)).variance()[seglabels.index('door')].item()\n",
    "          # / cond_changes.conditional(seglabels.index(gl)).size())\n",
    "        )\n",
    "        / baseline_door\n",
    "        for gl in glabels],\n",
    "        error_kw=dict(lw=1, capsize=5, capthick=1),\n",
    "        color=\"#4B4CBF\"\n",
    "      )\n",
    "ax.set_xticklabels(['']  + glabels)\n",
    "ax.set_yticklabels(['{:,.0%}'.format(x) for x in ax.get_yticks()])\n",
    "ax.set_ylabel('Added door area')\n",
    "ax.set_ylim([0,0.19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "(cond_changes.conditional(seglabels.index('window')).variance()[seglabels.index('door')].item()\n",
    "  / math.sqrt(cond_changes.conditional(seglabels.index('window')).size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "catcount = defaultdict(int)\n",
    "for _, cat in segcatlabels[1:]:\n",
    "    catcount[cat] += 1\n",
    "print(catcount)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}