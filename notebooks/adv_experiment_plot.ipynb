{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial attack experiment plots\n",
    "\n",
    "In this notebook, we will examine internal layer representations for a classifier trained to recognize scene categories.\n",
    "\n",
    "Setup matplotlib, torch, and numpy for a high-resolution browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from importlib import reload\n",
    "import IPython\n",
    "mpl.rcParams['lines.linewidth'] = 0.25\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.linewidth'] = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up experiment directory and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, argparse, os, shutil, inspect, json, numpy\n",
    "import netdissect\n",
    "from netdissect.easydict import EasyDict\n",
    "from netdissect import experiment\n",
    "from netdissect.experiment import resfile\n",
    "from netdissect import pbar, nethook, renormalize, parallelfolder, pidfile\n",
    "from netdissect import upsample, tally, imgviz, imgsave, bargraph, show\n",
    "reload(imgviz)\n",
    "# choices are alexnet, vgg16, or resnet152.\n",
    "args = EasyDict(model='vgg16', dataset='places', seg='netpqc', layer=None)\n",
    "resdir = 'results/%s-%s-%s' % (args.model, args.dataset, args.seg)\n",
    "experiment.set_result_dir(resdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load classifier model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = experiment.load_model(args)\n",
    "layername = experiment.instrumented_layername(args)\n",
    "model.retain_layer(layername)\n",
    "dataset = experiment.load_dataset(args)\n",
    "upfn = experiment.make_upfn(args, dataset, model, layername)\n",
    "sample_size = len(dataset)\n",
    "\n",
    "print('Inspecting layer %s of model %s on %s' % (layername, args.model, args.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier labels\n",
    "from urllib.request import urlopen\n",
    "from netdissect import renormalize\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "percent_level=0.995\n",
    "classlabels = dataset.classes\n",
    "renorm = renormalize.renormalizer(dataset, mode='zc')\n",
    "pbar.descnext('rq')\n",
    "def compute_samples(batch, *args):\n",
    "    image_batch = batch.cuda()\n",
    "    _ = model(image_batch)\n",
    "    acts = model.retained_layer(layername)\n",
    "    hacts = upfn(acts)\n",
    "    return hacts.permute(0, 2, 3, 1).contiguous().view(-1, acts.shape[1])\n",
    "rq = tally.tally_quantile(compute_samples, dataset,\n",
    "                          sample_size=sample_size,\n",
    "                          r=8192,\n",
    "                          num_workers=100,\n",
    "                          pin_memory=True,\n",
    "                          cachefile=resfile('rq.npz'))\n",
    "from netdissect import imgviz\n",
    "iv = imgviz.ImageVisualizer((100, 100), source=dataset, quantiles=rq, level=rq.quantiles(percent_level))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "def pickle_load(file_name):\n",
    "    data = None\n",
    "    with open(file_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate impact on imporant units from unimportant ones\n",
    "barchart_inc_mean = {}\n",
    "barchart_inc_err = {}\n",
    "barchart_other_mean = {}\n",
    "barchart_other_err = {}\n",
    "good_index_map = {}\n",
    "\n",
    "num_imp_units = 4\n",
    "num_images = 1000\n",
    "ci_99_factor = 2.58\n",
    "\n",
    "data = numpy.load('results/vgg16-places-netpqc-10/ttv_unit_ablation.npz')\n",
    "sua = torch.from_numpy(data['single_unit_ablation_ba'])\n",
    "base = torch.from_numpy(data['baseline_ba'])\n",
    "sua_diff = sua - base[None, :]\n",
    "\n",
    "expts = ['bedroom', 'computer_room', 'hangar-indoor', 'ski_resort', 'volleyball_court-outdoor']\n",
    "for target_class in expts:\n",
    "    class_id = classlabels.index(target_class)\n",
    "    all_unit_ids = sua_diff[:,class_id].sort(0)[1].numpy().tolist()\n",
    "    unit_ids = all_unit_ids[:num_imp_units]\n",
    "    other_ids = all_unit_ids[num_imp_units:]\n",
    "    good_indices = []\n",
    "    image_index = 0\n",
    "    while (True):\n",
    "        out = model(dataset[image_index][0][None,...].cuda())\n",
    "        gt_label = classlabels[dataset[image_index][1]]\n",
    "        pred_label = classlabels[out.max(1)[1][0]]\n",
    "        if gt_label != target_class and pred_label != target_class:\n",
    "            good_indices.append(image_index)\n",
    "        else:\n",
    "            print('image {:d} gt {:s} pred {:s}'.format(image_index, gt_label, pred_label))\n",
    "\n",
    "        image_index += 1\n",
    "        if len(good_indices) == num_images: \n",
    "            print('get {:d} images from {:d} candidates'.format(num_images, image_index))\n",
    "            break\n",
    "    # loading results \n",
    "    results_dir = 'results/adv/vgg16/{:s}_images'.format(target_class)\n",
    "    acts_mean_all = []\n",
    "    acts_mean_abs_all = []\n",
    "    acts_mean_mean_abs_all = []\n",
    "    acts_max_abs_all = []\n",
    "    for good_index in range(1010):\n",
    "        result_path = os.path.join(results_dir, 'image_{:d}_target_{:s}.pkl'.format(good_index, target_class))\n",
    "        try:\n",
    "            data = pickle_load(result_path)\n",
    "        except:\n",
    "            pass\n",
    "        image_id = data['image_id']\n",
    "        target_id = data['target_id']\n",
    "        ori_image = data['ori']\n",
    "        adv_image = data['adv']\n",
    "        pred_ori = model(dataset[image_id][0][None,...].cuda())\n",
    "        image_ori = dataset[image_id][0]\n",
    "        acts_ori = model.retained_layer(layername).cpu()\n",
    "\n",
    "        adv = renormalize.as_tensor(adv_image, source='pt', mode='imagenet')[None,...]\n",
    "        pred_adv = model(adv.cuda())\n",
    "\n",
    "        acts_adv = model.retained_layer(layername).cpu()\n",
    "\n",
    "        acts_mean_abs = (acts_adv - acts_ori).abs().mean(dim=(2, 3)).numpy()\n",
    "        acts_mean = (acts_adv - acts_ori).abs().mean(dim=(2, 3)).numpy()\n",
    "        acts_mean_all.append(acts_mean_abs)\n",
    "        acts_mean_abs_all.append(acts_mean_abs)\n",
    "        acts_mean_mean_abs_all.append((acts_adv.mean(3).mean(2) - acts_ori.mean(3).mean(2)).abs().numpy())\n",
    "        acts_max_abs_all.append((acts_adv.max(3)[0].max(2)[0] - acts_ori.max(3)[0].max(2)[0]).abs().numpy())\n",
    "    acts_max_abs_all = np.concatenate(acts_max_abs_all, axis=0)\n",
    "    # Store two things\n",
    "    important_changes = acts_max_abs_all[good_indices][:,unit_ids]\n",
    "    other_changes = acts_max_abs_all[good_indices][:,other_ids]\n",
    "    ic_mean = important_changes.mean()\n",
    "    oc_mean = other_changes.mean()\n",
    "    ic_err = important_changes.std() / numpy.sqrt(len(important_changes)) * ci_99_factor\n",
    "    oc_err = other_changes.std() / numpy.sqrt(len(other_changes)) * ci_99_factor\n",
    "    \n",
    "    barchart_inc_mean[target_class] = ic_mean\n",
    "    barchart_inc_err[target_class] = ic_err\n",
    "    barchart_other_mean[target_class] = oc_mean\n",
    "    barchart_other_err[target_class] = oc_err\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,2), dpi=300)\n",
    "ax.bar(np.arange(len(expts))-0.2,\n",
    "       [barchart_inc_mean[target_class] for target_class in expts],\n",
    "        width=0.28,\n",
    "        yerr=[barchart_inc_err[target_class] for target_class in expts],\n",
    "        error_kw=dict(lw=1, capsize=5, capthick=1),\n",
    "       color=\"#4B4CBF\",\n",
    "       label = \"4 most important units\"\n",
    "      )\n",
    "ax.bar(np.arange(len(expts))+0.2, \n",
    "       [barchart_other_mean[target_class] for target_class in expts],\n",
    "       width=0.28,\n",
    "        yerr=[barchart_other_err[target_class] for target_class in expts],\n",
    "        error_kw=dict(lw=1, capsize=5, capthick=1),\n",
    "       color=\"#F0883B\",\n",
    "       label = \"other units\"\n",
    "      )\n",
    "\n",
    "\n",
    "ax.set_ylabel('peak activation change')\n",
    "ax.set_xticks([0, 1, 2, 3])\n",
    "ax.set_xticklabels([{\n",
    "    'bedroom': 'bedroom',\n",
    "    'computer_room': 'computer room',\n",
    "    'hangar-indoor': 'hangar (indoor)',\n",
    "    'ski_resort': 'ski resort',\n",
    "    'volleyball_court-outdoor': 'volleyball court'}[e] for e in expts])\n",
    "ax.set_ylim(([0, 35]))\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(0.2, 1.0), edgecolor='None', facecolor='None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, urllib\n",
    "unit_names = json.load(urllib.request.urlopen('http://dissect.csail.mit.edu/results/vgg16-places-netpqc-conv5_3-10/report.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_class = 'ski_resort'\n",
    "class_id = classlabels.index(target_class)\n",
    "results_dir = 'results/adv/vgg16/{:s}_images'.format(target_class)\n",
    "all_unit_ids = sua_diff[:,class_id].sort(0)[1].numpy().tolist()\n",
    "unit_ids = all_unit_ids[:num_imp_units]\n",
    "other_ids = all_unit_ids[num_imp_units:]\n",
    "\n",
    "print(target_class, class_id)\n",
    "for good_index in [2, 18, 105, 111, 249, 262, 389, 478, 438, 538, 562, 653, 676, 878]:\n",
    "    try:\n",
    "        result_path = os.path.join(results_dir, 'image_{:d}_target_{:s}.pkl'.format(good_index, target_class))\n",
    "        data = pickle_load(result_path)\n",
    "    except:\n",
    "        continue\n",
    "    image_id = data['image_id']\n",
    "    target_id = data['target_id']\n",
    "    ori_image = data['ori']\n",
    "    adv_image = data['adv']\n",
    "    image_ori = dataset[image_id][0]\n",
    "    out = model(image_ori[None,...].cuda())\n",
    "    ori_classnum = out[0].max(0)[1].item()\n",
    "    ori_class = classlabels[ori_classnum]\n",
    "    acts_ori = model.retained_layer(layername).cpu()\n",
    "\n",
    "    adv = renormalize.as_tensor(adv_image, source='pt', mode='imagenet')[None,...]\n",
    "    pred_adv = model(adv.cuda())\n",
    "\n",
    "    acts_adv = model.retained_layer(layername).cpu()\n",
    "    acts_mean = (acts_adv - acts_ori).mean(dim=(2, 3)).numpy()[0]\n",
    "    acts_maxdelta = (acts_adv.view(acts_adv.shape[1],-1).max(-1)[0]\n",
    "                     - acts_ori.view(acts_adv.shape[1],-1).max(-1)[0])\n",
    "\n",
    "    raw_diff_image = adv_image - ori_image\n",
    "    diff_image = (raw_diff_image * 100 +0.5).clamp(0,1)\n",
    "    diff_zc_image = (raw_diff_image * 100).clamp(-1,1)\n",
    "    img = renormalize.as_image(diff_image, source='pt')\n",
    "\n",
    "    display(show.blocks([[['%d original' % good_index, ori_class], renormalize.as_image(image_ori, source='imagenet')],\n",
    "                        [['attack', 'delta'], renormalize.as_image(diff_zc_image, source='zc')],\n",
    "                        ] + [\n",
    "        [\n",
    "         ['%d %s' % (u, unit_names['units'][u]['label']),\n",
    "          '$\\Delta$ max %.2f' % acts_maxdelta[u].item()],\n",
    "         iv.masked_image(adv, acts_ori, (0, u), percent_level=0.99),\n",
    "         iv.masked_image(adv, acts_adv, (0, u), percent_level=0.99),\n",
    "         iv.masked_delta(adv, acts_adv - acts_ori, (0, u), above=10, below=-10)\n",
    "        ]\n",
    "        for u in unit_ids[:4]\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate impact on imporant units from unimportant ones\n",
    "barchart_target_mean = {}\n",
    "barchart_target_err = {}\n",
    "barchart_source_mean = {}\n",
    "barchart_source_err = {}\n",
    "barchart_other_mean = {}\n",
    "barchart_other_err = {}\n",
    "good_index_map = {}\n",
    "\n",
    "num_imp_units = 4\n",
    "num_images = 1000\n",
    "ci_99_factor = 2.58\n",
    "\n",
    "data = numpy.load('results/vgg16-places-netpqc-10/ttv_unit_ablation.npz')\n",
    "sua = torch.from_numpy(data['single_unit_ablation_ba'])\n",
    "base = torch.from_numpy(data['baseline_ba'])\n",
    "sua_diff = sua - base[None, :]\n",
    "top_units_by_class = sua_diff.sort(0)[1]\n",
    "\n",
    "expts = ['bedroom', 'computer_room', 'hangar-indoor', 'ski_resort', 'volleyball_court-outdoor']\n",
    "for target_class in expts:\n",
    "    class_id = classlabels.index(target_class)\n",
    "    good_indices = []\n",
    "    image_index = 0\n",
    "    while (True):\n",
    "        out = model(dataset[image_index][0][None,...].cuda())\n",
    "        gt_label = classlabels[dataset[image_index][1]]\n",
    "        pred_label = classlabels[out.max(1)[1][0]]\n",
    "        if gt_label != target_class and pred_label != target_class:\n",
    "            good_indices.append(image_index)\n",
    "        else:\n",
    "            print('image {:d} gt {:s} pred {:s}'.format(image_index, gt_label, pred_label))\n",
    "\n",
    "        image_index += 1\n",
    "        if len(good_indices) == num_images: \n",
    "            print('get {:d} images from {:d} candidates'.format(num_images, image_index))\n",
    "            break\n",
    "    # loading results \n",
    "    results_dir = 'results/adv/vgg16/{:s}_images'.format(target_class)\n",
    "    target_changes = []\n",
    "    source_changes = []\n",
    "    other_changes = []\n",
    "    for good_index in range(1010):\n",
    "        result_path = os.path.join(results_dir, 'image_{:d}_target_{:s}.pkl'.format(good_index, target_class))\n",
    "        try:\n",
    "            data = pickle_load(result_path)\n",
    "        except:\n",
    "            pass\n",
    "        image_id = data['image_id']\n",
    "        target_id = data['target_id']\n",
    "        ori_image = data['ori']\n",
    "        adv_image = data['adv']\n",
    "        pred_ori = model(dataset[image_id][0][None,...].cuda())\n",
    "        source_class = pred_ori.max(1)[1][0]\n",
    "        image_ori = dataset[image_id][0]\n",
    "        acts_ori = model.retained_layer(layername).cpu()\n",
    "\n",
    "        adv = renormalize.as_tensor(adv_image, source='pt', mode='imagenet')[None,...]\n",
    "        pred_adv = model(adv.cuda())\n",
    "\n",
    "        acts_adv = model.retained_layer(layername).cpu()\n",
    "\n",
    "        acts_max_diff = (acts_adv.max(3)[0].max(2)[0] - acts_ori.max(3)[0].max(2)[0]).abs()[0]\n",
    "        \n",
    "        target_unit_ids = top_units_by_class[:,class_id][:num_imp_units]\n",
    "        source_unit_ids = top_units_by_class[:,source_class][:num_imp_units]\n",
    "        other_unit_ids = torch.ones(512, dtype=torch.uint8)\n",
    "        other_unit_ids[target_unit_ids] = 0\n",
    "        other_unit_ids[source_unit_ids] = 0\n",
    "        \n",
    "        target_changes.extend(acts_max_diff[target_unit_ids].numpy().tolist())\n",
    "        source_changes.extend(acts_max_diff[source_unit_ids].numpy().tolist())\n",
    "        other_changes.extend(acts_max_diff[other_unit_ids].numpy().tolist())\n",
    "    \n",
    "    target_changes = numpy.array(target_changes)\n",
    "    source_changes = numpy.array(source_changes)\n",
    "    other_changes = numpy.array(other_changes)\n",
    "    \n",
    "    tc_mean = target_changes.mean()\n",
    "    sc_mean = source_changes.mean()\n",
    "    oc_mean = other_changes.mean()\n",
    "    tc_err = target_changes.std() / numpy.sqrt(len(target_changes)) * ci_99_factor\n",
    "    sc_err = source_changes.std() / numpy.sqrt(len(source_changes)) * ci_99_factor\n",
    "    oc_err = other_changes.std() / numpy.sqrt(len(other_changes)) * ci_99_factor\n",
    "    \n",
    "    barchart_target_mean[target_class] = tc_mean\n",
    "    barchart_target_err[target_class] = tc_err\n",
    "    barchart_source_mean[target_class] = sc_mean\n",
    "    barchart_source_err[target_class] = sc_err\n",
    "    barchart_other_mean[target_class] = oc_mean\n",
    "    barchart_other_err[target_class] = oc_err\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_changes.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,2.5), dpi=300)\n",
    "\n",
    "ax.bar(np.arange(len(expts))-0.25,\n",
    "       [barchart_target_mean[target_class] for target_class in expts],\n",
    "        width=0.2,\n",
    "        yerr=[barchart_target_err[target_class] for target_class in expts],\n",
    "        error_kw=dict(lw=1, capsize=5, capthick=1),\n",
    "       color=\"#4B4CBF\",\n",
    "       label = \"4 units most important to target class\"\n",
    "      )\n",
    "ax.bar(np.arange(len(expts)), \n",
    "       [barchart_source_mean[target_class] for target_class in expts],\n",
    "       width=0.2,\n",
    "        yerr=[barchart_source_err[target_class] for target_class in expts],\n",
    "        error_kw=dict(lw=1, capsize=5, capthick=1),\n",
    "       color=\"#F0883B\",\n",
    "       label = \"4 units most important to source class\"\n",
    "      )\n",
    "ax.bar(np.arange(len(expts))+0.25, \n",
    "       [barchart_other_mean[target_class] for target_class in expts],\n",
    "       width=0.2,\n",
    "        yerr=[barchart_other_err[target_class] for target_class in expts],\n",
    "        error_kw=dict(lw=1, capsize=5, capthick=1),\n",
    "       color='#55B05B',\n",
    "       label = \"other units\"\n",
    "      )\n",
    "\n",
    "ax.set_ylabel('peak activation change')\n",
    "ax.set_xlabel('target class for adversarial attack')\n",
    "ax.set_xticks([0, 1, 2, 3, 4])\n",
    "ax.set_xticklabels([{\n",
    "    'bedroom': 'bedroom',\n",
    "    'computer_room': 'computer room',\n",
    "    'hangar-indoor': 'hangar',\n",
    "    'ski_resort': 'ski resort',\n",
    "    'volleyball_court-outdoor': 'volleyball court'}[e] for e in expts])\n",
    "# ax.set_ylim(([0, 43]))\n",
    "ax.legend(ncol=2, edgecolor='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "target_class = 'bedroom'\n",
    "class_id = classlabels.index(target_class)\n",
    "results_dir = 'results/adv/vgg16/{:s}_images'.format(target_class)\n",
    "\n",
    "gilist = json.load(open('ski_resort_to_bedroom.json'))\n",
    "\n",
    "print(target_class, class_id)\n",
    "for good_index in gilist:\n",
    "    try:\n",
    "        result_path = os.path.join(results_dir, 'image_{:d}_target_{:s}.pkl'.format(good_index, target_class))\n",
    "        data = pickle_load(result_path)\n",
    "    except:\n",
    "        continue\n",
    "    image_id = data['image_id']\n",
    "    target_id = data['target_id']\n",
    "    ori_image = data['ori']\n",
    "    adv_image = data['adv']\n",
    "    image_ori = dataset[image_id][0]\n",
    "    out = model(image_ori[None,...].cuda())\n",
    "    ori_classnum = out[0].max(0)[1].item()\n",
    "    ori_class = classlabels[ori_classnum]\n",
    "    acts_ori = model.retained_layer(layername).cpu()\n",
    "\n",
    "    target_unit_ids = top_units_by_class[:,class_id][:num_imp_units].cpu().numpy()\n",
    "    source_unit_ids = top_units_by_class[:,ori_classnum][:num_imp_units].cpu().numpy()\n",
    "        \n",
    "    adv = renormalize.as_tensor(adv_image, source='pt', mode='imagenet')[None,...]\n",
    "    pred_adv = model(adv.cuda())\n",
    "\n",
    "    acts_adv = model.retained_layer(layername).cpu()\n",
    "    acts_maxdelta = (acts_adv.view(acts_adv.shape[1],-1).max(-1)[0]\n",
    "                     - acts_ori.view(acts_adv.shape[1],-1).max(-1)[0])\n",
    "\n",
    "    raw_diff_image = adv_image - ori_image\n",
    "    diff_image = (raw_diff_image * 100 +0.5).clamp(0,1)\n",
    "    diff_zc_image = (raw_diff_image * 100).clamp(-1,1)\n",
    "    img = renormalize.as_image(diff_image, source='pt')\n",
    "    \n",
    "    display(show.blocks([\n",
    "        ([['%d original' % good_index, ori_class], renormalize.as_image(image_ori, source='imagenet')],\n",
    "                        [['attack', 'delta'], renormalize.as_image(diff_zc_image, source='zc')],\n",
    "        ) +\n",
    "        tuple([\n",
    "            ['%d %s' % (u, unit_names['units'][u]['label']), '$\\Delta$ max %.2f' % acts_maxdelta[u].item()],\n",
    "            iv.masked_delta(adv, acts_adv - acts_ori, (0, u), above=10, below=-10)\n",
    "        ]\n",
    "        for u in source_unit_ids),\n",
    "        \n",
    "        ([['attacked', target_class], renormalize.as_image(adv_image, source='pt')],\n",
    "         [['attack', '-delta'], renormalize.as_image(-diff_zc_image, source='zc')]\n",
    "        ) +\n",
    "        tuple([['%d %s' % (u, unit_names['units'][u]['label']), '$\\Delta$ max %.2f' % acts_maxdelta[u].item()],\n",
    "          iv.masked_delta(adv, acts_adv - acts_ori, (0, u), above=10, below=-10)\n",
    "        ]\n",
    "        for u in target_unit_ids),        \n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_unit_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}