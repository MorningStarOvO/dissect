{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Dissection (for generators)\n",
    "\n",
    "In this notebook, we will examine internal layer representations for a generator trained via GAN.\n",
    "\n",
    "Setup matplotlib, torch, and numpy for a high-resolution browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from importlib import reload\n",
    "import IPython\n",
    "mpl.rcParams['lines.linewidth'] = 0.25\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.linewidth'] = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up experiment directory and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, argparse, os, shutil, inspect, json, numpy\n",
    "import netdissect\n",
    "from netdissect.easydict import EasyDict\n",
    "from netdissect import pbar, nethook, renormalize, parallelfolder, pidfile\n",
    "from netdissect import upsample, tally, imgviz, imgsave, bargraph, show\n",
    "from experiment import dissect_experiment as experiment\n",
    "# choices are alexnet, vgg16, or resnet152.\n",
    "args = EasyDict(model='progan', dataset='kitchen', seg='netpqc', layer='layer5', quantile=0.01)\n",
    "resdir = 'results/%s-%s-%s-%s-%s' % (args.model, args.dataset, args.seg, args.layer, int(args.quantile * 1000))\n",
    "def resfile(f):\n",
    "    return os.path.join(resdir, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load generator model and z dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from netdissect import zdataset\n",
    "model = experiment.load_model(args)\n",
    "layername = experiment.instrumented_layername(args)\n",
    "model.retain_layer(layername)\n",
    "# dataset = experiment.load_dataset(args, model.model)\n",
    "dataset = zdataset.z_dataset_for_model(model, size=10000, seed=1)\n",
    "\n",
    "upfn = experiment.make_upfn(args, dataset, model, layername)\n",
    "sample_size = len(dataset)\n",
    "percent_level = 1.0 - args.quantile\n",
    "\n",
    "print('Inspecting layer %s of model %s on %s' % (layername, args.model, args.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load segmenter, segment labels, classifier labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier labels\n",
    "segmodel, seglabels, segcatlabels = experiment.setting.load_segmenter(args.seg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test generator to make some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netdissect import renormalize\n",
    "\n",
    "indices = [200, 755, 489, 709, 423, 60, 100, 110, 120]\n",
    "batch = torch.cat([dataset[i][0][None,...] for i in indices])\n",
    "outs = model(batch.cuda())\n",
    "imgs = [renormalize.as_image(t) for t in outs]\n",
    "show([[img] for img in imgs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "segment single image, and visualize the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netdissect import imgviz\n",
    "\n",
    "iv = imgviz.ImageVisualizer(120)\n",
    "renorm = renormalize.renormalizer(target='zc')\n",
    "seg = segmodel.segment_batch(renorm(outs).cuda(), downsample=4)\n",
    "\n",
    "show([(iv.image(outs[i]), iv.segmentation(seg[i,0]),\n",
    "            iv.segment_key(seg[i,0], segmodel))\n",
    "            for i in range(len(seg))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize activations for single layer of single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netdissect import imgviz\n",
    "\n",
    "acts = model.retained_layer(layername).cpu()\n",
    "ivsmall = imgviz.ImageVisualizer((64,  64))\n",
    "display(show.blocks(\n",
    "    [[[ivsmall.masked_image(outs[0], acts, (0, u))],\n",
    "      [ivsmall.heatmap(acts, (0, u), mode='nearest')]] for u in range(min(acts.shape[1], 12))]\n",
    "))\n",
    "\n",
    "num_units = acts.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect quantile statistics\n",
    "\n",
    "First, unconditional quantiles over the activations.  We will upsample them to 56x56 to match with segmentations later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar.descnext('rq')\n",
    "def compute_samples(batch, *args):\n",
    "    z_batch = batch.cuda()\n",
    "    _ = model(z_batch)\n",
    "    acts = model.retained_layer(layername)\n",
    "    hacts = upfn(acts)\n",
    "    return hacts.permute(0, 2, 3, 1).contiguous().view(-1, acts.shape[1])\n",
    "rq = tally.tally_quantile(compute_samples, dataset,\n",
    "                          sample_size=sample_size,\n",
    "                          r=8192,\n",
    "                          num_workers=100,\n",
    "                          pin_memory=True,\n",
    "                          cachefile=resfile('rq.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Units\n",
    "\n",
    "Collect topk stats first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar.descnext('topk')\n",
    "def compute_image_max(batch, *args):\n",
    "    image_batch = batch.cuda()\n",
    "    _ = model(image_batch)\n",
    "    acts = model.retained_layer(layername)\n",
    "    acts = acts.view(acts.shape[0], acts.shape[1], -1)\n",
    "    acts = acts.max(2)[0]\n",
    "    return acts\n",
    "topk = tally.tally_topk(compute_image_max, dataset, sample_size=sample_size,\n",
    "        batch_size=50, num_workers=30, pin_memory=True,\n",
    "        cachefile=resfile('topk.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we just need to run through and visualize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar.descnext('unit_images')\n",
    "\n",
    "iv = imgviz.ImageVisualizer((256, 256), image_size=256, source='zc', quantiles=rq,\n",
    "        level=rq.quantiles(percent_level))\n",
    "def compute_acts(data_batch):\n",
    "    data_batch = data_batch.cuda()\n",
    "    image_batch = model(data_batch)\n",
    "    acts_batch = model.retained_layer(layername)\n",
    "    return acts_batch, image_batch\n",
    "unit_images = iv.masked_images_for_topk(\n",
    "        compute_acts, dataset, topk, k=4, num_workers=30, pin_memory=True,\n",
    "        cachefile=resfile('big-top4images.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in [15, 35]:\n",
    "    print('unit %d' % u)\n",
    "    display(unit_images[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_unit = 314\n",
    "selected_segment = seglabels.index('window')\n",
    "\n",
    "for i in [0, 10, 20, 30, 31, 33]:\n",
    "    batch = dataset[i][0][None,...].cuda()\n",
    "    img = model(batch)[0]\n",
    "    seg = segmodel.segment_batch(img[None,...])\n",
    "    seg = seg[0]\n",
    "    seg[seg != selected_segment] = 0\n",
    "    acts = model.retained_layer(layername)[0]\n",
    "    show([i, [iv.image(img)], [iv.segmentation(seg)], [iv.heatmap(acts, selected_unit, mode='nearest')]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Units\n",
    "\n",
    "Collect 99 quantile stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the segmodel for segmentations.  With broden, we could use ground truth instead.\n",
    "def compute_conditional_indicator(batch, *args):\n",
    "    image_batch = batch.cuda()\n",
    "    seg = segmodel.segment_batch(renorm(image_batch), downsample=4)\n",
    "    _ = model(image_batch)\n",
    "    acts = model.retained_layer(layername)\n",
    "    hacts = upfn(acts)\n",
    "    iacts = (hacts > level_at_99).float() # indicator\n",
    "    return tally.conditional_samples(iacts, seg)\n",
    "pbar.descnext('condi99')\n",
    "condi99 = tally.tally_conditional_mean(compute_conditional_indicator,\n",
    "        dataset, sample_size=sample_size,\n",
    "        num_workers=3, pin_memory=True,\n",
    "        cachefile=resfile('condi99.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_99 = tally.iou_from_conditional_indicator_mean(condi99)\n",
    "unit_label_99 = [\n",
    "        (concept.item(), seglabels[concept], segcatlabels[concept], bestiou.item())\n",
    "        for (bestiou, concept) in zip(*iou_99.max(0))]\n",
    "label_list = [labelcat for concept, label, labelcat, iou in unit_label_99 if iou > 0.04]\n",
    "display(IPython.display.SVG(experiment.graph_conceptcatlist(label_list)))\n",
    "len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a few units with their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_iou_units = sorted(enumerate(unit_label_99), key=lambda x: -x[1][-1])\n",
    "for urec in top_iou_units[:10]:\n",
    "    u = urec[0]\n",
    "    print('unit %d, label %s, iou %.3f' % (u, unit_label_99[u][1], unit_label_99[u][3]))\n",
    "    display(unit_images[u])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}